{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3937ab68-8f88-4ee6-b9a2-6965f1b476b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "pip install nltk pandas matplotlib scipy huggingface_hub pyarrow fsspec seaborn scikit-learn wordcloud -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d59b2f3-be94-4668-b47a-68dfd24b01db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "def tokenize(token):\n",
    "    return nltk.word_tokenize(token, language='english', preserve_line=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68751a4c-f841-4f0d-9802-10c30fc62d69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tokenize(\"why is this not working?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9065e2ad-122d-43bd-9197-14541e694186",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "# corpus de nltk para 'tokenizer' y 'stopwords'\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('words')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "da893e74-a788-4ed9-a2f5-eb894810d8b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## preprocesamiento de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63a01fcc-fda7-4e21-9d6d-fdbadccf82f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "splits = {'train': 'data/train-00000-of-00001-7b34565378f02992.parquet', 'val': 'data/val-00000-of-00001-d7338c59b5e5031f.parquet', 'test': 'data/test-00000-of-00001-c830a979da438bff.parquet'}\n",
    "df_train = pd.read_parquet(\"hf://datasets/PrevenIA/spanish-suicide-intent/\" + splits[\"train\"])\n",
    "df_val = pd.read_parquet(\"hf://datasets/PrevenIA/spanish-suicide-intent/\" + splits[\"val\"])\n",
    "df_test = pd.read_parquet(\"hf://datasets/PrevenIA/spanish-suicide-intent/\" + splits[\"test\"])\n",
    "\n",
    "df = pd.concat([df_train, df_val, df_test]).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a4a6ae9-3f54-4944-9896-fc7cd3b6ba20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df[\"Label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "79377c53-6210-4ae6-9b87-3561ddb468ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizing the text in each row\n",
    "df['tokenized_text'] = df['Text'].apply(lambda text: nltk.word_tokenize(str(text), language='spanish', preserve_line=True))\n",
    "\n",
    "# Counting the number of tokens in each row\n",
    "df['count_text'] = df['tokenized_text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c03d764-4aed-4e4e-83b4-9caa8b8421b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df['Label'] = df['Label'].astype('category')\n",
    "df[['count_text', 'Label']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28a2f62f-cd20-460c-9fff-2ded0d070bbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Función para identificar los outliers\n",
    "def find_outliers(df, column, label_column):\n",
    "    outliers = pd.DataFrame(columns=df.columns)\n",
    "    for label in df[label_column].unique():\n",
    "        subset = df[df[label_column] == label]\n",
    "        Q1 = subset[column].quantile(0.25)\n",
    "        Q3 = subset[column].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers_subset = subset[(subset[column] < lower_bound) | (subset[column] > upper_bound)]\n",
    "        outliers = pd.concat([outliers, outliers_subset])\n",
    "    return outliers\n",
    "\n",
    "# Suponiendo que los datos están en un DataFrame llamado 'df'\n",
    "# Crear el boxplot sin outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='Label', y='count_text', data=df, showfliers=False)\n",
    "plt.title('Boxplot de Palabras en post por etiqueta (sin outliers)')\n",
    "plt.xlabel('Etiqueta')\n",
    "plt.ylabel('Palabras por post')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b1e6b35-5fe3-484d-8d4e-246ce5b64950",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear el boxplot sin outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.boxplot(x='Label', y='count_text', data=df, showfliers=False)\n",
    "\n",
    "# Calcular la media y la mediana por cada grupo\n",
    "means = df.groupby('Label')['count_text'].mean()\n",
    "medians = df.groupby('Label')['count_text'].median()\n",
    "positions = range(len(means))\n",
    "\n",
    "# Agregar anotaciones de la media y la mediana\n",
    "for tick, label in zip(positions, ax.get_xticks()):\n",
    "    # Obtener la media y la mediana para este grupo\n",
    "    mean = means.iloc[tick]\n",
    "    median = medians.iloc[tick]\n",
    "    \n",
    "    # Anotar la media\n",
    "    ax.text(label, mean, f'Media: {mean:.1f}', horizontalalignment='center', verticalalignment='center', color='white', fontsize=10)\n",
    "    \n",
    "    # Anotar la mediana\n",
    "    ax.text(label, median, f'Mediana: {median:.1f}', horizontalalignment='center', verticalalignment='center', color='white', fontsize=10)\n",
    "\n",
    "# Títulos y etiquetas\n",
    "plt.title('Boxplot de Palabras en post por etiqueta (sin outliers)')\n",
    "plt.xlabel('Etiqueta')\n",
    "plt.ylabel('Palabras por post')\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a96fd99-37a8-4931-aa87-fe2c57671f26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Crear el gráfico KDE para cada etiqueta\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Graficar la distribución (KDE) para cada etiqueta\n",
    "sns.kdeplot(data=df, x='count_text', hue='Label', fill=True)\n",
    "\n",
    "# Limitar el rango del eje x para excluir los outliers\n",
    "plt.xlim(0, df['count_text'].quantile(0.99))  # Limitar al percentil 95\n",
    "\n",
    "# Títulos y etiquetas\n",
    "plt.title('Distribuciones de Palabras por Post por Etiqueta (KDE)')\n",
    "plt.xlabel('Palabras por post')\n",
    "plt.ylabel('Densidad')\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1773dbcf-7556-4428-ab6b-03613e8d05b8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Encontrar los outliers\n",
    "outliers = find_outliers(df, 'count_text', 'Label')\n",
    "\n",
    "# Contar el número de outliers por etiqueta\n",
    "outliers_count = outliers.groupby('Label').size()\n",
    "\n",
    "# Contar el total de observaciones por etiqueta\n",
    "total_count = df.groupby('Label').size()\n",
    "\n",
    "# Crear gráfico separado para los outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.stripplot(x='Label', y='count_text', data=outliers, color='red', marker='o', jitter=True)\n",
    "\n",
    "# Añadir una etiqueta que muestre el número de outliers y el porcentaje con respecto al total\n",
    "for label, count in outliers_count.items():\n",
    "    total = total_count[label]\n",
    "    percentage = (count / total) * 100\n",
    "    plt.text(label, outliers['count_text'].max() + 1, f'Outliers: {count} ({percentage:.2f}%)', \n",
    "             horizontalalignment='center', color='black', weight='bold')\n",
    "\n",
    "plt.title('Outliers de count_text por Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('count_text')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0c2a561d-e126-45c6-b8f9-dc0cac1cd937",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Combinar todos los textos en un solo string\n",
    "text = \" \".join(review for review in df['Text'])\n",
    "\n",
    "# Crear la nube de palabras\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "# Mostrar la nube de palabras\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fe8328a6-3f2b-44e7-9a28-15a4facecfef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    width=800, \n",
    "    height=400, \n",
    "    max_words=200, \n",
    "    background_color='white', \n",
    "    colormap='viridis',  # Cambiar el esquema de colores\n",
    "    stopwords=None,      # Puedes añadir tus propias stopwords\n",
    "    contour_color='steelblue', \n",
    "    contour_width=3\n",
    ").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3088d9d7-6157-4f62-896c-e6d97c0d58b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def unir_tokens_from_lista(lista_tokens:list)->list:\n",
    "    all_tokens = []\n",
    "    for t in lista_tokens:\n",
    "        all_tokens.extend(t)\n",
    "    print(\"all_tokens_title =\",len(all_tokens))\n",
    "    return all_tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23c74aad-f039-4927-ae3d-2da0136ba335",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def analisis_grafico(all_tokens: list, palabras_top: int = 10):\n",
    "    # Análisis de frecuencia en palabras \n",
    "    fdist = nltk.FreqDist(all_tokens)\n",
    "    print('Size BoW =', len(fdist))\n",
    "    \n",
    "    # Palabras más comunes\n",
    "    topwords = fdist.most_common(palabras_top)\n",
    "    x, y = zip(*topwords)\n",
    "    \n",
    "    # Crear gráfico\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.bar(x, y)\n",
    "    \n",
    "    # Rotar etiquetas del eje X\n",
    "    plt.xticks(rotation=90, fontsize=14)  # Aumenta el tamaño de las etiquetas en el eje X\n",
    "    plt.yticks(fontsize=14)  # Aumenta el tamaño de las etiquetas en el eje Y\n",
    "    \n",
    "    # Etiquetas de los ejes con tamaño de fuente aumentado\n",
    "    plt.xlabel('Palabras', fontsize=16)\n",
    "    plt.ylabel('Frecuencia', fontsize=16)\n",
    "    \n",
    "    # Mostrar gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "737f037b-7858-4aa3-9403-d6f41f547376",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import seaborn as sns\n",
    "\n",
    "def analisis_grafico_2(all_tokens: list, palabras_top: int = 10):\n",
    "    # Análisis de frecuencia en palabras\n",
    "    fdist = nltk.FreqDist(all_tokens)\n",
    "    print('Size BoW =', len(fdist))\n",
    "    \n",
    "    # Palabras más comunes\n",
    "    topwords = fdist.most_common(palabras_top)\n",
    "    x, y = zip(*topwords)\n",
    "    \n",
    "    # Crear gráfico\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Usar una paleta de colores de seaborn\n",
    "    palette = sns.color_palette(\"husl\", palabras_top)  # Cambia \"husl\" por otra paleta si lo prefieres\n",
    "    plt.bar(x, y, color=palette)\n",
    "    \n",
    "    # Rotar etiquetas del eje X\n",
    "    plt.xticks(rotation=90, fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    # Etiquetas de los ejes\n",
    "    plt.xlabel('Palabras', fontsize=16)\n",
    "    plt.ylabel('Frecuencia', fontsize=16)\n",
    "    \n",
    "    # Mostrar gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f305d689-83c3-4bad-9eed-456e2d353b2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def analisis_grafico_3(all_tokens: list, palabras_top: int = 10):\n",
    "    # Análisis de frecuencia en palabras\n",
    "    fdist = nltk.FreqDist(all_tokens)\n",
    "    print('Size BoW =', len(fdist))\n",
    "    \n",
    "    # Palabras más comunes\n",
    "    topwords = fdist.most_common(palabras_top)\n",
    "    x, y = zip(*topwords)\n",
    "    \n",
    "    # Crear gráfico de barras horizontales\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Usar un degradado de azul en la paleta de colores\n",
    "    palette = sns.light_palette(\"blue\", reverse=True, n_colors=palabras_top)  # Paleta en degradado azul\n",
    "    \n",
    "    # Graficar barras horizontales con el degradado\n",
    "    plt.barh(x, y, color=palette)\n",
    "    \n",
    "    # Invertir el eje Y para que el ranking se vea de mayor a menor\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # Ajustar el tamaño de las etiquetas\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "    \n",
    "    # Etiquetas de los ejes\n",
    "    plt.xlabel('Frecuencia', fontsize=16)\n",
    "    plt.ylabel('Palabras', fontsize=16)\n",
    "    \n",
    "    # Mostrar gráfico\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f04aa022-f2a8-477b-ac48-41f3fc17ac6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lista_intencion_suicidio = df[df[\"Label\"]==1][\"tokenized_text\"].values\n",
    "all_tokens = unir_tokens_from_lista(lista_intencion_suicidio)\n",
    "analisis_grafico_3(all_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f08d8bf1-244a-49c2-9558-657d2ed6e7c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### preprocesamiento inicial y elimininacion de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a374a7d6-937b-4b18-8d47-15b9ba1a730f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "def quitar_tildes(s):  \n",
    "    s = re.sub(r'[áàä]', 'a', s)  \n",
    "    s = re.sub(r'[éèë]', 'e', s)  \n",
    "    s = re.sub(r'[íìï]', 'i', s)  \n",
    "    s = re.sub(r'[óòö]', 'o', s)  \n",
    "    s = re.sub(r'[úùü]', 'u', s)  \n",
    "    return s  \n",
    "\n",
    "def preprocesamiento_and_stopwords(all_tokens):\n",
    "    stop_words_nltk = set(stopwords.words('spanish'))\n",
    "    prepro_tokens = [quitar_tildes(w) for w in all_tokens]\n",
    "    prepro_tokens = [w.lower() for w in prepro_tokens]  \n",
    "    prepro_tokens = [re.sub(r'[^A-Za-z0-9]+','',w) for w in prepro_tokens]\n",
    "    prepro_tokens = [w for w in prepro_tokens if w not in stop_words_nltk]\n",
    "    prepro_tokens = [w for w in prepro_tokens if w.isalpha()]\n",
    "    prepro_tokens = [w for w in prepro_tokens if len(w)>3]\n",
    "    return prepro_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d452f2e0-528b-44a6-9b33-2d7778204ece",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prepro_tokens = preprocesamiento_and_stopwords(all_tokens)\n",
    "analisis_grafico_3(prepro_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46d09561-401f-40e7-9be3-483dfc51d71e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combinar todos los textos en un solo string\n",
    "text = \" \".join(prepro_tokens)\n",
    "\n",
    "# Crear la nube de palabras\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "# Mostrar la nube de palabras\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63265cf2-e0ec-4612-888a-23a79bb04e35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### lematizacion y stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e7db151d-4f9b-4ef0-b66e-84e068dfdddd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Lemmatization y stemmer\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "def preprocesamiento_lematizacion_stemming(tokens):\n",
    "    lancaster = LancasterStemmer()\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    prepro_tokens = [wordnet_lemmatizer.lemmatize(w, pos=\"v\") for w in tokens ]\n",
    "    prepro_tokens = [wordnet_lemmatizer.lemmatize(w, pos=\"n\") for w in prepro_tokens ]\n",
    "    prepro_tokens = [wordnet_lemmatizer.lemmatize(w, pos=\"a\") for w in prepro_tokens ]\n",
    "    prepro_tokens = [wordnet_lemmatizer.lemmatize(w, pos=\"r\") for w in prepro_tokens ]\n",
    "\n",
    "    prepro_tokens = [lancaster.stem(w) for w in prepro_tokens]\n",
    "    prepro_tokens = [w for w in prepro_tokens if len(w)>2]\n",
    "\n",
    "    return prepro_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d31eb78e-1f83-4b0e-a322-10ff082ebca6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prepro_tokens = preprocesamiento_lematizacion_stemming(prepro_tokens)\n",
    "analisis_grafico(prepro_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f910723-0c8f-4041-ad66-6b85ae146d2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combinar todos los textos en un solo string\n",
    "text = \" \".join(prepro_tokens)\n",
    "\n",
    "# Crear la nube de palabras\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "# Mostrar la nube de palabras\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "22429394-1c82-4ca8-959a-e4449b4009f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Matriz de frecuencia de terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fb31c26a-05e3-47ca-b703-fd705ce34406",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def crear_matriz_frecuencia_terminos(prepro_tokens: list):\n",
    "    vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words=None)\n",
    "    \n",
    "    # Matriz dispersa de frecuencia de términos\n",
    "    X = vectorizer.fit_transform(prepro_tokens)\n",
    "    \n",
    "    # Obtener el vocabulario\n",
    "    T = vectorizer.get_feature_names_out()\n",
    "\n",
    "    return X, T\n",
    "\n",
    "def extraer_topicos_con_LDA(X, T, numero_topicos=5, numero_terminos=10):\n",
    "    lda = LatentDirichletAllocation(n_components=numero_topicos, random_state=42)\n",
    "    lda.fit(X)\n",
    "\n",
    "    # Mostrar los términos más importantes por cada tópico\n",
    "    for idx, topic in enumerate(lda.components_):\n",
    "        print(f\"Tópico {idx + 1}:\")\n",
    "        top_terminos = [T[i] for i in topic.argsort()[:-numero_terminos - 1:-1]]\n",
    "        print(\" \".join(top_terminos))\n",
    "\n",
    "\n",
    "X, T = crear_matriz_frecuencia_terminos(prepro_tokens)\n",
    "extraer_topicos_con_LDA(X, T, numero_topicos=5, numero_terminos=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7a128a37-8a9a-4091-b9a9-7ae6c41a64f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "extraer_topicos_con_LDA(X, T, numero_topicos=5, numero_terminos=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "964676d8-57bf-43a9-803d-8a4e242f95a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lista_intencion_suicidio = df[\"tokenized_text\"].values\n",
    "all_tokens = unir_tokens_from_lista(lista_intencion_suicidio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9053041-1aac-4110-9cd3-41f291339645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "prepro_tokens = preprocesamiento_and_stopwords(all_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1915cd17-ce16-4798-9bb9-d9d58346790a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "len(prepro_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3c049edc-64ff-4616-b377-dd5dd309b50d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X, T = crear_matriz_frecuencia_terminos(prepro_tokens)\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dbccbc09-7201-4c58-b1c0-29ee6ca47521",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "extraer_topicos_con_LDA(X, T, numero_topicos=5, numero_terminos=10)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "EDA_trainig_data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
